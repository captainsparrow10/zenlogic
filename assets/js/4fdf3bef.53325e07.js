"use strict";(globalThis.webpackChunkerp_docs=globalThis.webpackChunkerp_docs||[]).push([[993],{4626:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"integraciones/rabbitmq","title":"RabbitMQ - Message Broker","description":"Integraci\xf3n con RabbitMQ para comunicaci\xf3n as\xedncrona basada en eventos.","source":"@site/docs/04-integraciones/01-rabbitmq.md","sourceDirName":"04-integraciones","slug":"/integraciones/rabbitmq","permalink":"/zenlogic/integraciones/rabbitmq","draft":false,"unlisted":false,"editUrl":"https://github.com/your-repo/edit/main/docs/04-integraciones/01-rabbitmq.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docs","previous":{"title":"Integraciones - Overview","permalink":"/zenlogic/integraciones/overview"},"next":{"title":"Redis - Cache y Sesiones","permalink":"/zenlogic/integraciones/redis"}}');var s=a(4848),r=a(8453);const i={sidebar_position:2},o="RabbitMQ - Message Broker",c={},l=[{value:"Overview",id:"overview",level:2},{value:"Configuraci\xf3n",id:"configuraci\xf3n",level:2},{value:"Instalaci\xf3n",id:"instalaci\xf3n",level:3},{value:"Variables de Entorno",id:"variables-de-entorno",level:3},{value:"Estructura de Exchange y Queues",id:"estructura-de-exchange-y-queues",level:2},{value:"Exchange Principal",id:"exchange-principal",level:3},{value:"Declaraci\xf3n de Exchange",id:"declaraci\xf3n-de-exchange",level:3},{value:"Declaraci\xf3n de Queues",id:"declaraci\xf3n-de-queues",level:3},{value:"Publisher (Publicador de Eventos)",id:"publisher-publicador-de-eventos",level:2},{value:"Implementaci\xf3n",id:"implementaci\xf3n",level:3},{value:"Uso del Publisher",id:"uso-del-publisher",level:3},{value:"Consumer (Consumidor de Eventos)",id:"consumer-consumidor-de-eventos",level:2},{value:"Implementaci\xf3n",id:"implementaci\xf3n-1",level:3},{value:"Uso del Consumer",id:"uso-del-consumer",level:3},{value:"Dead Letter Queue (DLQ)",id:"dead-letter-queue-dlq",level:2},{value:"Configuraci\xf3n",id:"configuraci\xf3n-1",level:3},{value:"Monitoreo de DLQ",id:"monitoreo-de-dlq",level:3},{value:"Patrones Avanzados",id:"patrones-avanzados",level:2},{value:"Idempotencia",id:"idempotencia",level:3},{value:"Event Replay",id:"event-replay",level:3},{value:"Monitoreo",id:"monitoreo",level:2},{value:"M\xe9tricas Prometheus",id:"m\xe9tricas-prometheus",level:3},{value:"Health Check",id:"health-check",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Problema: Mensajes no se consumen",id:"problema-mensajes-no-se-consumen",level:3},{value:"Problema: Memory leak en RabbitMQ",id:"problema-memory-leak-en-rabbitmq",level:3},{value:"Pr\xf3ximos Pasos",id:"pr\xf3ximos-pasos",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"rabbitmq---message-broker",children:"RabbitMQ - Message Broker"})}),"\n",(0,s.jsx)(n.p,{children:"Integraci\xf3n con RabbitMQ para comunicaci\xf3n as\xedncrona basada en eventos."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"RabbitMQ es el message broker central para la arquitectura event-driven de zenLogic. Todos los microservicios publican eventos de negocio que otros servicios pueden consumir de manera desacoplada."}),"\n",(0,s.jsx)(n.mermaid,{value:"graph LR\n    Auth[Auth Service] --\x3e|publish| Exchange[erp.events<br/>Topic Exchange]\n    Catalog[Catalog Service] --\x3e|publish| Exchange\n\n    Exchange --\x3e|route| Q1[catalog.events<br/>Queue]\n    Exchange --\x3e|route| Q2[audit.events<br/>Queue]\n\n    Q1 --\x3e|consume| Catalog\n    Q2 --\x3e|consume| Audit[Audit Service]"}),"\n",(0,s.jsx)(n.h2,{id:"configuraci\xf3n",children:"Configuraci\xf3n"}),"\n",(0,s.jsx)(n.h3,{id:"instalaci\xf3n",children:"Instalaci\xf3n"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Docker Compose\nversion: \'3.8\'\nservices:\n  rabbitmq:\n    image: rabbitmq:3.12-management\n    ports:\n      - "5672:5672"      # AMQP\n      - "15672:15672"    # Management UI\n    environment:\n      RABBITMQ_DEFAULT_USER: admin\n      RABBITMQ_DEFAULT_PASS: admin123\n    volumes:\n      - rabbitmq_data:/var/lib/rabbitmq\n\nvolumes:\n  rabbitmq_data:\n'})}),"\n",(0,s.jsx)(n.h3,{id:"variables-de-entorno",children:"Variables de Entorno"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# .env\nRABBITMQ_URL=amqp://admin:admin123@localhost:5672/\nRABBITMQ_EXCHANGE=erp.events\nRABBITMQ_EXCHANGE_TYPE=topic\n"})}),"\n",(0,s.jsx)(n.h2,{id:"estructura-de-exchange-y-queues",children:"Estructura de Exchange y Queues"}),"\n",(0,s.jsx)(n.h3,{id:"exchange-principal",children:"Exchange Principal"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# Exchange: erp.events (tipo: topic)\n# Routing keys: {service}.{entity}.{action}\n\n# Ejemplos:\n# - auth.user.created\n# - auth.user.deactivated\n# - auth.local.created\n# - catalog.product.created\n# - catalog.product.updated\n# - catalog.variant.created\n"})}),"\n",(0,s.jsx)(n.h3,{id:"declaraci\xf3n-de-exchange",children:"Declaraci\xf3n de Exchange"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import aio_pika\n\nasync def declare_exchange(channel: aio_pika.Channel):\n    """Declarar exchange principal."""\n\n    exchange = await channel.declare_exchange(\n        name="erp.events",\n        type=aio_pika.ExchangeType.TOPIC,\n        durable=True  # Persiste en disco\n    )\n\n    return exchange\n'})}),"\n",(0,s.jsx)(n.h3,{id:"declaraci\xf3n-de-queues",children:"Declaraci\xf3n de Queues"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def declare_queue(\n    channel: aio_pika.Channel,\n    queue_name: str,\n    routing_keys: list[str]\n):\n    """Declarar queue con bindings."""\n\n    # Declarar exchange\n    exchange = await channel.declare_exchange(\n        "erp.events",\n        aio_pika.ExchangeType.TOPIC,\n        durable=True\n    )\n\n    # Declarar queue con DLQ\n    queue = await channel.declare_queue(\n        queue_name,\n        durable=True,\n        arguments={\n            "x-dead-letter-exchange": "dlx.events",\n            "x-dead-letter-routing-key": f"{queue_name}.dead",\n            "x-message-ttl": 3600000  # 1 hora\n        }\n    )\n\n    # Bind routing keys\n    for routing_key in routing_keys:\n        await queue.bind(exchange, routing_key=routing_key)\n\n    logger.info(f"Queue \'{queue_name}\' declared with bindings: {routing_keys}")\n    return queue\n'})}),"\n",(0,s.jsx)(n.h2,{id:"publisher-publicador-de-eventos",children:"Publisher (Publicador de Eventos)"}),"\n",(0,s.jsx)(n.h3,{id:"implementaci\xf3n",children:"Implementaci\xf3n"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# app/events/publisher.py\nimport aio_pika\nimport json\nfrom uuid import uuid4\nfrom datetime import datetime\nfrom typing import Dict, Any\nfrom app.config import settings\n\nclass EventPublisher:\n    """Publicador de eventos a RabbitMQ."""\n\n    def __init__(self):\n        self.connection = None\n        self.channel = None\n        self.exchange = None\n\n    async def connect(self):\n        """Conectar a RabbitMQ."""\n\n        self.connection = await aio_pika.connect_robust(\n            settings.rabbitmq_url,\n            heartbeat=60  # Heartbeat cada 60 segundos\n        )\n\n        self.channel = await self.connection.channel()\n\n        # Habilitar publisher confirms\n        await self.channel.set_qos(prefetch_count=1)\n\n        # Declarar exchange\n        self.exchange = await self.channel.declare_exchange(\n            settings.rabbitmq_exchange,\n            aio_pika.ExchangeType.TOPIC,\n            durable=True\n        )\n\n        logger.info(f"Connected to RabbitMQ: {settings.rabbitmq_url}")\n\n    async def publish(\n        self,\n        event_type: str,\n        payload: Dict[str, Any],\n        metadata: Dict[str, Any] = None\n    ):\n        """\n        Publicar evento.\n\n        Args:\n            event_type: Tipo de evento (routing key)\n            payload: Datos del evento\n            metadata: Metadata adicional (user_id, correlation_id, etc.)\n        """\n\n        # Construir evento\n        event = {\n            "event_id": str(uuid4()),\n            "event_type": event_type,\n            "timestamp": datetime.utcnow().isoformat(),\n            "service": settings.service_name,\n            "version": "1.0",\n            "payload": payload,\n            "metadata": metadata or {}\n        }\n\n        # Serializar\n        message_body = json.dumps(event, default=str).encode()\n\n        # Crear mensaje\n        message = aio_pika.Message(\n            body=message_body,\n            delivery_mode=aio_pika.DeliveryMode.PERSISTENT,  # Persistente\n            content_type="application/json",\n            message_id=event["event_id"],\n            timestamp=datetime.utcnow()\n        )\n\n        # Publicar\n        await self.exchange.publish(\n            message,\n            routing_key=event_type\n        )\n\n        logger.info(\n            f"Event published: {event_type}",\n            extra={"event_id": event["event_id"]}\n        )\n\n        # M\xe9tricas\n        events_published.labels(event_type=event_type).inc()\n\n    async def close(self):\n        """Cerrar conexi\xf3n."""\n        if self.connection:\n            await self.connection.close()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"uso-del-publisher",children:"Uso del Publisher"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# app/main.py\nfrom app.events.publisher import EventPublisher\n\n# Inicializar\nevent_publisher = EventPublisher()\n\n@app.on_event("startup")\nasync def startup():\n    await event_publisher.connect()\n\n@app.on_event("shutdown")\nasync def shutdown():\n    await event_publisher.close()\n\n# En endpoints\n@router.post("/products")\nasync def create_product(product: ProductCreate):\n    # Crear producto en DB\n    new_product = await product_service.create(product)\n\n    # Publicar evento\n    await event_publisher.publish(\n        event_type="catalog.product.created",\n        payload={\n            "product_id": str(new_product.id),\n            "organization_id": str(new_product.organization_id),\n            "name": new_product.name,\n            "sku": new_product.sku,\n            "base_price": float(new_product.base_price)\n        },\n        metadata={\n            "user_id": current_user.id,\n            "correlation_id": request.state.correlation_id\n        }\n    )\n\n    return new_product\n'})}),"\n",(0,s.jsx)(n.h2,{id:"consumer-consumidor-de-eventos",children:"Consumer (Consumidor de Eventos)"}),"\n",(0,s.jsx)(n.h3,{id:"implementaci\xf3n-1",children:"Implementaci\xf3n"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# app/events/consumer.py\nimport aio_pika\nimport json\nimport asyncio\nfrom typing import Callable, Dict\nfrom app.config import settings\n\nclass EventConsumer:\n    """Consumidor de eventos de RabbitMQ."""\n\n    def __init__(\n        self,\n        queue_name: str,\n        routing_keys: list[str],\n        handlers: Dict[str, Callable]\n    ):\n        self.queue_name = queue_name\n        self.routing_keys = routing_keys\n        self.handlers = handlers\n        self.connection = None\n        self.channel = None\n\n    async def start(self):\n        """Iniciar consumidor."""\n\n        # Conectar\n        self.connection = await aio_pika.connect_robust(\n            settings.rabbitmq_url,\n            heartbeat=60\n        )\n\n        self.channel = await self.connection.channel()\n\n        # QoS: procesar 10 mensajes en paralelo\n        await self.channel.set_qos(prefetch_count=10)\n\n        # Declarar exchange\n        exchange = await self.channel.declare_exchange(\n            settings.rabbitmq_exchange,\n            aio_pika.ExchangeType.TOPIC,\n            durable=True\n        )\n\n        # Declarar queue\n        queue = await self.channel.declare_queue(\n            self.queue_name,\n            durable=True,\n            arguments={\n                "x-dead-letter-exchange": "dlx.events",\n                "x-message-ttl": 3600000\n            }\n        )\n\n        # Bind routing keys\n        for routing_key in self.routing_keys:\n            await queue.bind(exchange, routing_key=routing_key)\n\n        # Consumir\n        await queue.consume(self.process_message)\n\n        logger.info(\n            f"Consumer started: {self.queue_name}",\n            extra={"routing_keys": self.routing_keys}\n        )\n\n    async def process_message(self, message: aio_pika.IncomingMessage):\n        """Procesar mensaje recibido."""\n\n        async with message.process(ignore_processed=True):\n            try:\n                # Parsear evento\n                event = json.loads(message.body.decode())\n                event_type = event["event_type"]\n\n                logger.info(\n                    f"Processing event: {event_type}",\n                    extra={"event_id": event.get("event_id")}\n                )\n\n                # Buscar handler\n                handler = self.handlers.get(event_type)\n\n                if handler:\n                    # Ejecutar handler\n                    await handler(event)\n\n                    # ACK\n                    await message.ack()\n\n                    # M\xe9tricas\n                    events_consumed.labels(\n                        event_type=event_type,\n                        status="success"\n                    ).inc()\n\n                    logger.info(f"Event processed successfully: {event_type}")\n                else:\n                    logger.warning(f"No handler for event: {event_type}")\n                    await message.ack()  # ACK anyway\n\n            except Exception as e:\n                logger.error(\n                    f"Error processing event: {e}",\n                    exc_info=True\n                )\n\n                # NACK con requeue\n                await message.nack(requeue=True)\n\n                # M\xe9tricas\n                events_consumed.labels(\n                    event_type=event.get("event_type", "unknown"),\n                    status="error"\n                ).inc()\n\n    async def stop(self):\n        """Detener consumidor."""\n        if self.connection:\n            await self.connection.close()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"uso-del-consumer",children:"Uso del Consumer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# app/main.py\nfrom app.events.consumer import EventConsumer\nfrom app.handlers import event_handlers\n\n# Definir handlers\nevent_handlers = {\n    "auth.user.created": handle_user_created,\n    "auth.user.deactivated": handle_user_deactivated,\n    "auth.local.created": handle_local_created,\n}\n\n# Inicializar consumer\nconsumer = EventConsumer(\n    queue_name="catalog.events",\n    routing_keys=["auth.user.*", "auth.local.*"],\n    handlers=event_handlers\n)\n\n@app.on_event("startup")\nasync def startup():\n    # Iniciar consumer en background\n    asyncio.create_task(consumer.start())\n\n@app.on_event("shutdown")\nasync def shutdown():\n    await consumer.stop()\n\n# Handlers\nasync def handle_user_created(event: dict):\n    """Handler para auth.user.created."""\n    payload = event["payload"]\n    logger.info(f"User created: {payload[\'user_id\']}")\n\n    # L\xf3gica de negocio\n    # ...\n\nasync def handle_local_created(event: dict):\n    """Handler para auth.local.created."""\n    payload = event["payload"]\n\n    # Invalidar cache de locales\n    await redis.delete(f"org:{payload[\'organization_id\']}:locals")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"dead-letter-queue-dlq",children:"Dead Letter Queue (DLQ)"}),"\n",(0,s.jsx)(n.h3,{id:"configuraci\xf3n-1",children:"Configuraci\xf3n"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def setup_dlq(channel: aio_pika.Channel):\n    """Configurar Dead Letter Exchange y Queue."""\n\n    # DLX Exchange\n    dlx = await channel.declare_exchange(\n        "dlx.events",\n        aio_pika.ExchangeType.TOPIC,\n        durable=True\n    )\n\n    # DLQ Queue\n    dlq = await channel.declare_queue(\n        "dlq.events",\n        durable=True\n    )\n\n    # Bind all dead letters\n    await dlq.bind(dlx, routing_key="#")\n\n    logger.info("DLQ configured")\n'})}),"\n",(0,s.jsx)(n.h3,{id:"monitoreo-de-dlq",children:"Monitoreo de DLQ"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def check_dlq_size():\n    """Verificar tama\xf1o de DLQ."""\n\n    async with aio_pika.connect_robust(settings.rabbitmq_url) as connection:\n        channel = await connection.channel()\n        queue = await channel.declare_queue("dlq.events", passive=True)\n\n        message_count = queue.declaration_result.message_count\n\n        if message_count > 100:\n            logger.warning(\n                f"DLQ has {message_count} messages!",\n                extra={"dlq_size": message_count}\n            )\n\n            # Alerta\n            send_alert(f"DLQ size: {message_count}")\n'})}),"\n",(0,s.jsx)(n.h2,{id:"patrones-avanzados",children:"Patrones Avanzados"}),"\n",(0,s.jsx)(n.h3,{id:"idempotencia",children:"Idempotencia"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'# Tabla de eventos procesados\nCREATE TABLE processed_events (\n    event_id UUID PRIMARY KEY,\n    event_type VARCHAR(100),\n    processed_at TIMESTAMP DEFAULT NOW()\n);\n\n# Handler idempotente\nasync def handle_event_idempotent(event: dict):\n    event_id = event["event_id"]\n\n    # Verificar si ya fue procesado\n    existing = await db.execute(\n        select(ProcessedEvent).where(ProcessedEvent.event_id == event_id)\n    )\n\n    if existing.scalar():\n        logger.info(f"Event {event_id} already processed, skipping")\n        return\n\n    # Procesar evento\n    await process_event(event)\n\n    # Registrar como procesado\n    await db.execute(\n        insert(ProcessedEvent).values(\n            event_id=event_id,\n            event_type=event["event_type"]\n        )\n    )\n    await db.commit()\n'})}),"\n",(0,s.jsx)(n.h3,{id:"event-replay",children:"Event Replay"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'async def replay_events(start_date: datetime, end_date: datetime):\n    """Replay de eventos hist\xf3ricos."""\n\n    # Obtener eventos de Audit Service\n    events = await audit_service.get_events(\n        start_date=start_date,\n        end_date=end_date\n    )\n\n    # Republicar\n    for event in events:\n        await event_publisher.publish(\n            event_type=event["event_type"],\n            payload=event["payload"],\n            metadata={\n                **event.get("metadata", {}),\n                "replayed": True,\n                "original_timestamp": event["timestamp"]\n            }\n        )\n'})}),"\n",(0,s.jsx)(n.h2,{id:"monitoreo",children:"Monitoreo"}),"\n",(0,s.jsx)(n.h3,{id:"m\xe9tricas-prometheus",children:"M\xe9tricas Prometheus"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from prometheus_client import Counter, Histogram, Gauge\n\nevents_published = Counter(\n    "events_published_total",\n    "Total events published",\n    ["event_type"]\n)\n\nevents_consumed = Counter(\n    "events_consumed_total",\n    "Total events consumed",\n    ["event_type", "status"]\n)\n\nevent_processing_duration = Histogram(\n    "event_processing_seconds",\n    "Event processing duration",\n    ["event_type"]\n)\n\nrabbitmq_queue_size = Gauge(\n    "rabbitmq_queue_size",\n    "Current queue size",\n    ["queue_name"]\n)\n'})}),"\n",(0,s.jsx)(n.h3,{id:"health-check",children:"Health Check"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'@router.get("/health/rabbitmq")\nasync def rabbitmq_health():\n    """Health check de RabbitMQ."""\n\n    try:\n        async with aio_pika.connect_robust(\n            settings.rabbitmq_url,\n            timeout=5.0\n        ) as connection:\n            if connection.is_closed:\n                raise Exception("Connection closed")\n\n            return {"status": "healthy"}\n\n    except Exception as e:\n        return JSONResponse(\n            {"status": "unhealthy", "error": str(e)},\n            status_code=503\n        )\n'})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"problema-mensajes-no-se-consumen",children:"Problema: Mensajes no se consumen"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Causas"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Consumer no est\xe1 corriendo"}),"\n",(0,s.jsx)(n.li,{children:"Routing key incorrecto en binding"}),"\n",(0,s.jsx)(n.li,{children:"Mensaje en DLQ"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Soluci\xf3n"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Verificar queues\ncurl -u admin:admin123 http://localhost:15672/api/queues\n\n# Ver DLQ\ncurl -u admin:admin123 http://localhost:15672/api/queues/%2F/dlq.events\n\n# Purgar DLQ si es necesario\ncurl -u admin:admin123 -X DELETE \\\n  http://localhost:15672/api/queues/%2F/dlq.events/contents\n"})}),"\n",(0,s.jsx)(n.h3,{id:"problema-memory-leak-en-rabbitmq",children:"Problema: Memory leak en RabbitMQ"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Causas"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Mensajes no se consumen"}),"\n",(0,s.jsx)(n.li,{children:"Muchos mensajes en queues"}),"\n",(0,s.jsx)(n.li,{children:"Falta de flow control"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Soluci\xf3n"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Ver uso de memoria\nrabbitmqctl status\n\n# Configurar memory alarms\nrabbitmqctl set_vm_memory_high_watermark 0.6  # 60%\n"})}),"\n",(0,s.jsx)(n.h2,{id:"pr\xf3ximos-pasos",children:"Pr\xf3ximos Pasos"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/integraciones/redis",children:"Redis - Cache"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/adrs/adr-003-event-driven",children:"ADR-003: Event-Driven Architecture"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/microservicios/catalog-service/eventos-consumidos",children:"Catalog Service - Eventos Consumidos"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>i,x:()=>o});var t=a(6540);const s={},r=t.createContext(s);function i(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);