"use strict";(globalThis.webpackChunkerp_docs=globalThis.webpackChunkerp_docs||[]).push([[5846],{956:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"microservicios/audit-service/retention-policy","title":"Retention Policy","description":"Pol\xedticas de retenci\xf3n y archivado de logs de auditor\xeda.","source":"@site/docs/02-microservicios/audit-service/06-retention-policy.md","sourceDirName":"02-microservicios/audit-service","slug":"/microservicios/audit-service/retention-policy","permalink":"/zenlogic/microservicios/audit-service/retention-policy","draft":false,"unlisted":false,"editUrl":"https://github.com/your-repo/edit/main/docs/02-microservicios/audit-service/06-retention-policy.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"docs","previous":{"title":"API Logs","permalink":"/zenlogic/microservicios/audit-service/api-logs"},"next":{"title":"Queries Comunes","permalink":"/zenlogic/microservicios/audit-service/queries-comunes"}}');var o=i(4848),t=i(8453);const r={sidebar_position:7},s="Retention Policy",d={},c=[{value:"Pol\xedticas de Retenci\xf3n",id:"pol\xedticas-de-retenci\xf3n",level:2},{value:"Niveles de Retenci\xf3n",id:"niveles-de-retenci\xf3n",level:3},{value:"Implementaci\xf3n",id:"implementaci\xf3n",level:2},{value:"Cronjob de Archivado",id:"cronjob-de-archivado",level:3},{value:"Configuraci\xf3n de Cronjob",id:"configuraci\xf3n-de-cronjob",level:3},{value:"Configuraci\xf3n de Variables",id:"configuraci\xf3n-de-variables",level:3},{value:"Recuperaci\xf3n de Logs Archivados",id:"recuperaci\xf3n-de-logs-archivados",level:2},{value:"Script de Restauraci\xf3n",id:"script-de-restauraci\xf3n",level:3},{value:"Compresi\xf3n de Particiones",id:"compresi\xf3n-de-particiones",level:2},{value:"Vacuum y Analyze",id:"vacuum-y-analyze",level:3},{value:"Monitoreo de Espacio",id:"monitoreo-de-espacio",level:2},{value:"Configuraci\xf3n de Alerts",id:"configuraci\xf3n-de-alerts",level:2},{value:"Pr\xf3ximos Pasos",id:"pr\xf3ximos-pasos",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"retention-policy",children:"Retention Policy"})}),"\n",(0,o.jsx)(n.p,{children:"Pol\xedticas de retenci\xf3n y archivado de logs de auditor\xeda."}),"\n",(0,o.jsx)(n.h2,{id:"pol\xedticas-de-retenci\xf3n",children:"Pol\xedticas de Retenci\xf3n"}),"\n",(0,o.jsx)(n.h3,{id:"niveles-de-retenci\xf3n",children:"Niveles de Retenci\xf3n"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:"Hot Storage (PostgreSQL):\n  Duration: 90 d\xedas\n  Access: Inmediato\n  Performance: Alta\n  Cost: Alto\n\nWarm Storage (Compressed):\n  Duration: 1 a\xf1o\n  Access: Medio (descompresi\xf3n requerida)\n  Performance: Media\n  Cost: Medio\n\nCold Storage (S3/Archive):\n  Duration: 2+ a\xf1os\n  Access: Lento\n  Performance: Baja\n  Cost: Bajo\n"})}),"\n",(0,o.jsx)(n.h2,{id:"implementaci\xf3n",children:"Implementaci\xf3n"}),"\n",(0,o.jsx)(n.h3,{id:"cronjob-de-archivado",children:"Cronjob de Archivado"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom datetime import datetime, timedelta\nfrom sqlalchemy import select, delete\nfrom app.models.audit import AuditLog\nfrom app.database import get_db\n\nclass RetentionPolicy:\n    """Gesti\xf3n de retenci\xf3n de logs."""\n\n    def __init__(self, db_session):\n        self.db = db_session\n\n    async def archive_old_logs(self, days: int = 90):\n        """\n        Archivar logs m\xe1s antiguos que X d\xedas.\n\n        1. Exportar a archivo comprimido\n        2. Subir a S3\n        3. Eliminar de PostgreSQL\n        """\n        cutoff_date = datetime.utcnow() - timedelta(days=days)\n\n        # Seleccionar logs a archivar\n        query = select(AuditLog).where(\n            AuditLog.created_at < cutoff_date\n        )\n        result = await self.db.execute(query)\n        logs_to_archive = result.scalars().all()\n\n        if not logs_to_archive:\n            logger.info("No logs to archive")\n            return 0\n\n        # Exportar a JSON comprimido\n        archive_file = await self.export_to_file(logs_to_archive)\n\n        # Subir a S3\n        await self.upload_to_s3(archive_file)\n\n        # Eliminar de DB (IMPORTANTE: bypass trigger de inmutabilidad)\n        await self.delete_archived_logs(cutoff_date)\n\n        logger.info(f"Archived {len(logs_to_archive)} logs older than {days} days")\n        return len(logs_to_archive)\n\n    async def export_to_file(self, logs: list) -> str:\n        """Exportar logs a archivo JSON.gz."""\n        import gzip\n        import json\n        from pathlib import Path\n\n        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")\n        filename = f"audit_logs_{timestamp}.json.gz"\n        filepath = Path("/tmp") / filename\n\n        # Convertir a JSON\n        logs_data = [\n            {\n                "id": str(log.id),\n                "event_id": log.event_id,\n                "event_type": log.event_type,\n                "created_at": log.created_at.isoformat(),\n                "service": log.service,\n                "payload": log.payload,\n                "metadata": log.metadata,\n                "organization_id": str(log.organization_id) if log.organization_id else None,\n                "user_id": str(log.user_id) if log.user_id else None\n            }\n            for log in logs\n        ]\n\n        # Comprimir\n        with gzip.open(filepath, \'wt\', encoding=\'utf-8\') as f:\n            json.dump(logs_data, f)\n\n        logger.info(f"Exported {len(logs)} logs to {filepath}")\n        return str(filepath)\n\n    async def upload_to_s3(self, filepath: str):\n        """Subir archivo a S3."""\n        import boto3\n        from config.settings import settings\n\n        s3 = boto3.client(\'s3\')\n        bucket = settings.s3_audit_bucket\n        key = f"audit_archives/{Path(filepath).name}"\n\n        s3.upload_file(filepath, bucket, key)\n\n        logger.info(f"Uploaded {filepath} to s3://{bucket}/{key}")\n\n        # Eliminar archivo temporal\n        Path(filepath).unlink()\n\n    async def delete_archived_logs(self, cutoff_date: datetime):\n        """Eliminar logs archivados de PostgreSQL."""\n\n        # IMPORTANTE: Necesita permisos especiales para bypass triggers\n        query = delete(AuditLog).where(\n            AuditLog.created_at < cutoff_date\n        )\n\n        await self.db.execute(query)\n        await self.db.commit()\n'})}),"\n",(0,o.jsx)(n.h3,{id:"configuraci\xf3n-de-cronjob",children:"Configuraci\xf3n de Cronjob"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'# app/tasks/retention.py\n\nfrom apscheduler.schedulers.asyncio import AsyncIOScheduler\nfrom app.services.retention import RetentionPolicy\n\nscheduler = AsyncIOScheduler()\n\n@scheduler.scheduled_job(\'cron\', hour=2)  # 2 AM diario\nasync def run_retention_policy():\n    """Ejecutar pol\xedtica de retenci\xf3n diariamente."""\n\n    async with get_db() as db:\n        retention = RetentionPolicy(db)\n\n        # Archivar logs > 90 d\xedas\n        archived = await retention.archive_old_logs(days=90)\n\n        logger.info(f"Retention policy executed: {archived} logs archived")\n'})}),"\n",(0,o.jsx)(n.h3,{id:"configuraci\xf3n-de-variables",children:"Configuraci\xf3n de Variables"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# .env\nS3_AUDIT_BUCKET=erp-audit-archives\nS3_REGION=us-east-1\nAWS_ACCESS_KEY_ID=your_key\nAWS_SECRET_ACCESS_KEY=your_secret\n\n# Retention settings\nAUDIT_RETENTION_DAYS=90\nAUDIT_ARCHIVE_ENABLED=true\n"})}),"\n",(0,o.jsx)(n.h2,{id:"recuperaci\xf3n-de-logs-archivados",children:"Recuperaci\xf3n de Logs Archivados"}),"\n",(0,o.jsx)(n.h3,{id:"script-de-restauraci\xf3n",children:"Script de Restauraci\xf3n"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import gzip\nimport json\nimport boto3\nfrom app.models.audit import AuditLog\n\nasync def restore_from_archive(archive_filename: str):\n    """Restaurar logs desde archivo S3."""\n\n    # Descargar de S3\n    s3 = boto3.client(\'s3\')\n    local_path = f"/tmp/{archive_filename}"\n\n    s3.download_file(\n        settings.s3_audit_bucket,\n        f"audit_archives/{archive_filename}",\n        local_path\n    )\n\n    # Descomprimir y cargar\n    with gzip.open(local_path, \'rt\', encoding=\'utf-8\') as f:\n        logs_data = json.load(f)\n\n    # Restaurar en DB\n    async with get_db() as db:\n        for log_data in logs_data:\n            audit_log = AuditLog(\n                id=log_data["id"],\n                event_id=log_data["event_id"],\n                event_type=log_data["event_type"],\n                created_at=datetime.fromisoformat(log_data["created_at"]),\n                service=log_data["service"],\n                payload=log_data["payload"],\n                metadata=log_data["metadata"],\n                organization_id=log_data["organization_id"],\n                user_id=log_data["user_id"]\n            )\n            db.add(audit_log)\n\n        await db.commit()\n\n    logger.info(f"Restored {len(logs_data)} logs from {archive_filename}")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"compresi\xf3n-de-particiones",children:"Compresi\xf3n de Particiones"}),"\n",(0,o.jsx)(n.h3,{id:"vacuum-y-analyze",children:"Vacuum y Analyze"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'async def compress_old_partitions():\n    """Comprimir particiones antiguas."""\n\n    # VACUUM FULL en particiones viejas\n    partitions = await get_old_partitions(days=60)\n\n    for partition in partitions:\n        await db.execute(f"VACUUM FULL {partition}")\n        await db.execute(f"ANALYZE {partition}")\n\n        logger.info(f"Compressed partition: {partition}")\n'})}),"\n",(0,o.jsx)(n.h2,{id:"monitoreo-de-espacio",children:"Monitoreo de Espacio"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from prometheus_client import Gauge\n\naudit_db_size_bytes = Gauge(\n    "audit_db_size_bytes",\n    "Tama\xf1o de la base de datos de auditor\xeda"\n)\n\nasync def monitor_db_size():\n    """Monitorear tama\xf1o de DB."""\n\n    query = """\n    SELECT pg_database_size(\'erp_audit\') as size_bytes\n    """\n\n    result = await db.execute(query)\n    size = result.scalar()\n\n    audit_db_size_bytes.set(size)\n'})}),"\n",(0,o.jsx)(n.h2,{id:"configuraci\xf3n-de-alerts",children:"Configuraci\xf3n de Alerts"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-yaml",children:'# Prometheus alerts\n- alert: AuditDBSizeHigh\n  expr: audit_db_size_bytes > 50 * 1024 * 1024 * 1024  # 50GB\n  annotations:\n    summary: "Base de datos de auditor\xeda muy grande"\n    description: "Considerar archivar logs antiguos"\n'})}),"\n",(0,o.jsx)(n.h2,{id:"pr\xf3ximos-pasos",children:"Pr\xf3ximos Pasos"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/microservicios/audit-service/queries-comunes",children:"Queries Comunes"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/microservicios/audit-service/event-consumer",children:"Event Consumer"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/microservicios/audit-service/api-logs",children:"API Logs"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>s});var a=i(6540);const o={},t=a.createContext(o);function r(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);