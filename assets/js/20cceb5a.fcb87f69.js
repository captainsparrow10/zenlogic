"use strict";(globalThis.webpackChunkerp_docs=globalThis.webpackChunkerp_docs||[]).push([[472],{8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(6540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},9273:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"microservicios/audit-service/event-consumer","title":"Event Consumer","description":"Implementaci\xf3n del consumidor de eventos para Audit Service.","source":"@site/docs/02-microservicios/audit-service/04-event-consumer.md","sourceDirName":"02-microservicios/audit-service","slug":"/microservicios/audit-service/event-consumer","permalink":"/zenlogic/microservicios/audit-service/event-consumer","draft":false,"unlisted":false,"editUrl":"https://github.com/your-repo/edit/main/docs/02-microservicios/audit-service/04-event-consumer.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"docs","previous":{"title":"Modelo de Datos","permalink":"/zenlogic/microservicios/audit-service/modelo-datos"},"next":{"title":"API Logs","permalink":"/zenlogic/microservicios/audit-service/api-logs"}}');var a=t(4848),s=t(8453);const r={sidebar_position:5},o="Event Consumer",c={},d=[{value:"Configuraci\xf3n de Queue",id:"configuraci\xf3n-de-queue",level:2},{value:"Implementaci\xf3n",id:"implementaci\xf3n",level:2},{value:"Consumer Principal",id:"consumer-principal",level:3},{value:"Service Layer",id:"service-layer",level:2},{value:"Repository Layer",id:"repository-layer",level:2},{value:"Batch Processing",id:"batch-processing",level:2},{value:"Manejo de Errores",id:"manejo-de-errores",level:2},{value:"Dead Letter Queue",id:"dead-letter-queue",level:3},{value:"Retry Logic",id:"retry-logic",level:3},{value:"M\xe9tricas",id:"m\xe9tricas",level:2},{value:"Pr\xf3ximos Pasos",id:"pr\xf3ximos-pasos",level:2}];function l(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"event-consumer",children:"Event Consumer"})}),"\n",(0,a.jsx)(n.p,{children:"Implementaci\xf3n del consumidor de eventos para Audit Service."}),"\n",(0,a.jsx)(n.h2,{id:"configuraci\xf3n-de-queue",children:"Configuraci\xf3n de Queue"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'QUEUE_NAME = "audit_service_queue"\nEXCHANGES = ["auth_events", "catalog_events", "inventory_events", "order_events"]\nROUTING_KEY = "#"  # Wildcard - todos los eventos\nPREFETCH_COUNT = 50\n'})}),"\n",(0,a.jsx)(n.h2,{id:"implementaci\xf3n",children:"Implementaci\xf3n"}),"\n",(0,a.jsx)(n.h3,{id:"consumer-principal",children:"Consumer Principal"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import aio_pika\nimport json\nimport asyncio\nfrom typing import Dict, Any\nfrom config.settings import settings\nfrom app.services.audit_service import AuditService\n\nclass AuditEventConsumer:\n    """Consumer de eventos para Audit Service."""\n\n    def __init__(self, audit_service: AuditService):\n        self.audit_service = audit_service\n        self.connection = None\n        self.channel = None\n        self.queue = None\n\n    async def connect(self):\n        """Conectar a RabbitMQ y configurar queue."""\n        self.connection = await aio_pika.connect_robust(\n            settings.rabbitmq_url,\n            loop=asyncio.get_event_loop()\n        )\n\n        self.channel = await self.connection.channel()\n        await self.channel.set_qos(prefetch_count=50)\n\n        # Declarar queue durable\n        self.queue = await self.channel.declare_queue(\n            "audit_service_queue",\n            durable=True,\n            arguments={\n                "x-message-ttl": 3600000,  # 1 hora\n                "x-dead-letter-exchange": "audit_dlq"\n            }\n        )\n\n        # Bind a m\xfaltiples exchanges\n        for exchange_name in ["auth_events", "catalog_events", "inventory_events", "order_events"]:\n            exchange = await self.channel.declare_exchange(\n                exchange_name,\n                aio_pika.ExchangeType.TOPIC,\n                durable=True\n            )\n            await self.queue.bind(exchange, routing_key="#")\n\n        logger.info("Audit Consumer connected to RabbitMQ")\n\n    async def start_consuming(self):\n        """Iniciar consumo de eventos."""\n        if not self.queue:\n            await self.connect()\n\n        logger.info("Starting to consume audit events...")\n\n        async with self.queue.iterator() as queue_iter:\n            async for message in queue_iter:\n                await self.process_message(message)\n\n    async def process_message(self, message: aio_pika.IncomingMessage):\n        """Procesar mensaje recibido."""\n        async with message.process(ignore_processed=True):\n            try:\n                # Parse event\n                event = json.loads(message.body.decode())\n\n                # Store event\n                await self.audit_service.store_event(event)\n\n                # Metrics\n                audit_events_consumed.labels(\n                    event_type=event.get("event_type", "unknown"),\n                    status="success"\n                ).inc()\n\n                # Log\n                logger.info(\n                    "Event stored",\n                    extra={\n                        "event_type": event.get("event_type"),\n                        "event_id": event.get("metadata", {}).get("correlation_id")\n                    }\n                )\n\n                # ACK message\n                await message.ack()\n\n            except json.JSONDecodeError as e:\n                logger.error(f"Invalid JSON in message: {e}")\n                await message.reject(requeue=False)  # DLQ\n\n            except Exception as e:\n                logger.error(f"Error processing message: {e}")\n                audit_events_consumed.labels(\n                    event_type="unknown",\n                    status="error"\n                ).inc()\n\n                # Requeue para retry\n                await message.nack(requeue=True)\n\n    async def close(self):\n        """Cerrar conexi\xf3n."""\n        if self.connection:\n            await self.connection.close()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"service-layer",children:"Service Layer"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from app.repositories.audit_repository import AuditRepository\nfrom app.schemas.audit import AuditLogCreate\nfrom typing import Dict, Any\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass AuditService:\n    """Servicio de auditor\xeda."""\n\n    def __init__(self, audit_repo: AuditRepository):\n        self.audit_repo = audit_repo\n\n    async def store_event(self, event: Dict[str, Any]):\n        """\n        Almacenar evento de auditor\xeda.\n\n        Args:\n            event: Evento completo con payload y metadata\n        """\n        # Generar event_id para idempotencia\n        event_id = event.get("metadata", {}).get("correlation_id")\n        if not event_id:\n            event_id = f"{event[\'event_type\']}_{event[\'timestamp\']}"\n\n        # Verificar si ya existe (idempotencia)\n        existing = await self.audit_repo.find_by_event_id(event_id)\n        if existing:\n            logger.debug(f"Event {event_id} already exists, skipping")\n            return existing\n\n        # Extraer datos del evento\n        audit_data = AuditLogCreate(\n            event_id=event_id,\n            event_type=event["event_type"],\n            service=event["service"],\n            version=event.get("version", "1.0"),\n            payload=event["payload"],\n            metadata=event.get("metadata", {}),\n            organization_id=event["payload"].get("organization_id"),\n            user_id=event.get("metadata", {}).get("user_id"),\n            ip_address=event.get("metadata", {}).get("ip_address"),\n            user_agent=event.get("metadata", {}).get("user_agent")\n        )\n\n        # Almacenar\n        audit_log = await self.audit_repo.create(audit_data)\n\n        logger.info(\n            f"Audit log created: {audit_log.id}",\n            extra={\n                "event_type": audit_log.event_type,\n                "organization_id": str(audit_log.organization_id) if audit_log.organization_id else None\n            }\n        )\n\n        return audit_log\n'})}),"\n",(0,a.jsx)(n.h2,{id:"repository-layer",children:"Repository Layer"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy import select\nfrom app.models.audit import AuditLog\nfrom app.schemas.audit import AuditLogCreate\nfrom typing import Optional\n\nclass AuditRepository:\n    """Repositorio para logs de auditor\xeda."""\n\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def create(self, audit_data: AuditLogCreate) -> AuditLog:\n        """Crear nuevo log de auditor\xeda."""\n        audit_log = AuditLog(**audit_data.model_dump())\n        self.db.add(audit_log)\n        await self.db.commit()\n        await self.db.refresh(audit_log)\n        return audit_log\n\n    async def find_by_event_id(self, event_id: str) -> Optional[AuditLog]:\n        """Buscar log por event_id (para idempotencia)."""\n        query = select(AuditLog).where(AuditLog.event_id == event_id)\n        result = await self.db.execute(query)\n        return result.scalar_one_or_none()\n\n    async def bulk_create(self, events: list[AuditLogCreate]) -> int:\n        """Crear m\xfaltiples logs en batch."""\n        audit_logs = [AuditLog(**event.model_dump()) for event in events]\n        self.db.add_all(audit_logs)\n        await self.db.commit()\n        return len(audit_logs)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"batch-processing",children:"Batch Processing"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import asyncio\nfrom collections import deque\nfrom datetime import datetime, timedelta\n\nclass BatchAuditConsumer(AuditEventConsumer):\n    """Consumer con batch processing para mejor performance."""\n\n    def __init__(self, audit_service: AuditService):\n        super().__init__(audit_service)\n        self.batch = deque()\n        self.batch_size = 100\n        self.batch_timeout = 0.5  # 500ms\n        self.last_flush = datetime.now()\n\n    async def process_message(self, message: aio_pika.IncomingMessage):\n        """Acumular en batch."""\n        try:\n            event = json.loads(message.body.decode())\n            self.batch.append((event, message))\n\n            # Flush si batch lleno o timeout\n            if len(self.batch) >= self.batch_size or \\\n               datetime.now() - self.last_flush > timedelta(seconds=self.batch_timeout):\n                await self.flush_batch()\n\n        except Exception as e:\n            logger.error(f"Error in batch processing: {e}")\n            await message.nack(requeue=True)\n\n    async def flush_batch(self):\n        """Guardar batch en DB."""\n        if not self.batch:\n            return\n\n        events_to_store = []\n        messages_to_ack = []\n\n        # Preparar eventos\n        for event, message in self.batch:\n            events_to_store.append(event)\n            messages_to_ack.append(message)\n\n        try:\n            # Bulk insert\n            await self.audit_service.bulk_store_events(events_to_store)\n\n            # ACK todos los mensajes\n            for message in messages_to_ack:\n                await message.ack()\n\n            logger.info(f"Flushed batch of {len(events_to_store)} events")\n\n        except Exception as e:\n            logger.error(f"Error flushing batch: {e}")\n            # NACK todos\n            for message in messages_to_ack:\n                await message.nack(requeue=True)\n\n        finally:\n            self.batch.clear()\n            self.last_flush = datetime.now()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"manejo-de-errores",children:"Manejo de Errores"}),"\n",(0,a.jsx)(n.h3,{id:"dead-letter-queue",children:"Dead Letter Queue"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'async def setup_dlq():\n    """Configurar Dead Letter Queue."""\n    channel = await connection.channel()\n\n    # DLQ Exchange\n    dlq_exchange = await channel.declare_exchange(\n        "audit_dlq",\n        aio_pika.ExchangeType.DIRECT,\n        durable=True\n    )\n\n    # DLQ Queue\n    dlq_queue = await channel.declare_queue(\n        "audit_dlq_queue",\n        durable=True\n    )\n\n    await dlq_queue.bind(dlq_exchange, routing_key="audit_dlq")\n'})}),"\n",(0,a.jsx)(n.h3,{id:"retry-logic",children:"Retry Logic"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from tenacity import retry, stop_after_attempt, wait_exponential\n\n@retry(\n    stop=stop_after_attempt(3),\n    wait=wait_exponential(multiplier=1, min=2, max=10)\n)\nasync def store_event_with_retry(event: dict):\n    """Almacenar evento con reintentos."""\n    await audit_service.store_event(event)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"m\xe9tricas",children:"M\xe9tricas"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from prometheus_client import Counter, Histogram\n\n# Contador de eventos consumidos\naudit_events_consumed = Counter(\n    "audit_events_consumed_total",\n    "Total eventos consumidos",\n    ["event_type", "status"]\n)\n\n# Latencia de procesamiento\naudit_processing_duration = Histogram(\n    "audit_processing_duration_seconds",\n    "Duraci\xf3n de procesamiento de eventos"\n)\n\n# Uso\nwith audit_processing_duration.time():\n    await audit_service.store_event(event)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"pr\xf3ximos-pasos",children:"Pr\xf3ximos Pasos"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/microservicios/audit-service/api-logs",children:"API Logs"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/microservicios/audit-service/modelo-datos",children:"Modelo de Datos"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/microservicios/audit-service/retention-policy",children:"Retention Policy"})}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}}}]);